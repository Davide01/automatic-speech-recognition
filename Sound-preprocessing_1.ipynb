{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/site-packages (from librosa)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/site-packages (from librosa)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/site-packages (from librosa)\n",
      "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/site-packages (from librosa)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/site-packages (from librosa)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/site-packages (from librosa)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/site-packages (from librosa)\n",
      "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/site-packages (from librosa)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/site-packages (from librosa)\n",
      "Requirement already satisfied: llvmlite>=0.26.0dev0 in /usr/local/lib/python3.6/site-packages (from numba>=0.38.0->librosa)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from jiwer)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pytorch\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/41/4487bc23e3ac4d674943176f5aa309427b011e00607eb98899e9d951f67b/pytorch-0.1.2.tar.gz\n",
      "Building wheels for collected packages: pytorch\n",
      "  Running setup.py bdist_wheel for pytorch ... \u001b[?25lerror\n",
      "  Complete output from command /usr/local/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-r0mhif2a/pytorch/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/tmpb5iffa45pip-wheel- --python-tag cp36:\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"/tmp/pip-build-r0mhif2a/pytorch/setup.py\", line 17, in <module>\n",
      "      raise Exception(message)\n",
      "  Exception: You should install pytorch from http://pytorch.org\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for pytorch\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Installing collected packages: pytorch\n",
      "  Running setup.py install for pytorch ... \u001b[?25lerror\n",
      "    Complete output from command /usr/local/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-r0mhif2a/pytorch/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-pgdwczz7-record/install-record.txt --single-version-externally-managed --compile:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-build-r0mhif2a/pytorch/setup.py\", line 13, in <module>\n",
      "        raise Exception(message)\n",
      "    Exception: You should install pytorch from http://pytorch.org\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"/usr/local/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-r0mhif2a/pytorch/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-pgdwczz7-record/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-build-r0mhif2a/pytorch/\u001b[0m\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "import io\n",
    "!pip install librosa\n",
    "!pip install jiwer\n",
    "!pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import torch\n",
    "#from torch.nn import CTCLoss\n",
    "from warpctc_pytorch import CTCLoss\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "import itertools\n",
    "#import jiwer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for file manipulation\n",
    "def load_samples(file_path):\n",
    "    ys, srs = [[]],[[]]\n",
    "    i = 0\n",
    "    #loads .wav files\n",
    "    for filename in os.listdir(file_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            y, sr = librosa.load(file_path+filename, sr=16000)\n",
    "            ys[i].append(y)\n",
    "            srs[i].append(sr)\n",
    "            i = i + 1\n",
    "            ys.append([])\n",
    "            srs.append([])  \n",
    "    ys = ys[0: len(ys) - 1]\n",
    "    srs = srs[0: len(srs) - 1]\n",
    "    return (ys, srs)\n",
    "\n",
    "\n",
    "def load_labels(file_path):\n",
    "    i = 0\n",
    "    labels = [[]]\n",
    "    \n",
    "    for filename in os.listdir(file_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file = open(file_path+filename, \"r\") \n",
    "            labels[i].append(file.read())\n",
    "            labels.append([])\n",
    "            i = i + 1\n",
    "            \n",
    "    labels=labels[0: len(labels) - 1]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for feature extraction\n",
    "def find_max(ys):\n",
    "    \"\"\"\n",
    "    Searches for the longest same.\n",
    "    used for padding.\n",
    "    ys - [num_samples] x [sample_length]\n",
    "    \n",
    "    returns\n",
    "    max(sample_length)\n",
    "    \"\"\"\n",
    "    \n",
    "    maximum =0\n",
    "    for y1 in ys:\n",
    "        for y2 in y1:\n",
    "            dim = y2.shape[0]\n",
    "            if dim > maximum:\n",
    "                maximum = dim\n",
    "    return maximum\n",
    "\n",
    "def pad_signal(ys, max_length):\n",
    "    \"\"\"\n",
    "    pads the signal\n",
    "    \n",
    "    Signals are not of the same length, so samples that are shorter then longest signal are padded\n",
    "    ys - [num_samples] x [sample_length]\n",
    "    \n",
    "    returns\n",
    "    [num_samples] x [sample_length] - sample_length is now same for each sample\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ys_new = ys\n",
    "    for i, y1 in enumerate(ys_new):\n",
    "        for j, y2 in enumerate(y1):\n",
    "            if len(y2) < max_length:\n",
    "                z = numpy.zeros((max_length - len(y2)))\n",
    "                pad_signal = numpy.append(y2, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "                ys_new[i][j] = pad_signal\n",
    "    return ys_new\n",
    "def pre_emphasize(ys, pre_emphasis = 0.97):\n",
    "    \"\"\"\n",
    "    Performs pre emphasis\n",
    "    \n",
    "    ys - ys - input array of all samples [num_samples] x [sample_length]\n",
    "    pre_emphasis - pre emphasis factor, usually 0.97\n",
    "    \n",
    "    returns\n",
    "    [num_samples] x [sample_length] - emphasized signal\n",
    "    \"\"\"\n",
    "    for i, y in enumerate(ys):\n",
    "        signal=y[0]\n",
    "        y[0] = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "    return ys\n",
    "def fourier_transform(ys, N_FFT=512, window='hamming', hop_size=256):\n",
    "    \"\"\"\n",
    "    Performs stft\n",
    "    \n",
    "    ys - input array of all samples [num_samples] x [sample_length]\n",
    "    N_FFT - number of FFTs\n",
    "    window - window function - e.g. hanning, or hamming etc.\n",
    "    hop_size - self explanatory\n",
    "    \n",
    "    returns Ds [num_samples] x [1] x [sequence_length] x [N_FFT/2 + 1] - returns spectrogram of the sample. It is a bit stupid, since there is one extra\n",
    "    unncessary dimension, it`s mostly because working with numpy arrays is ... \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Ds = [[]]\n",
    "\n",
    "    for i, y in enumerate(ys):\n",
    "        Ds[i].append(librosa.core.stft(y=y[0], n_fft=N_FFT, window=window, hop_length=hop_size))\n",
    "        Ds.append([])\n",
    "    return Ds\n",
    "\n",
    "def mfccs(ys, N_FFT=512, sr=16000, n_mfcc=40, hop_size=256):\n",
    "    \"\"\"\n",
    "    Extracts mel features\n",
    "    \n",
    "    ys - input array of all samples [num_samples] x [sample_length]\n",
    "    N_FFT - number of FFTs\n",
    "    sr - sampling rate\n",
    "    n_mfcc - number of mfcc features\n",
    "    hop_size - self explanatory\n",
    "    \n",
    "    returns\n",
    "    mels [num_samples] x [1] x [sequence_length] x [n_mfcc] - returns mel features. It is a bit stupid, since there is one extra\n",
    "    unncessary dimension, it`s mostly because working with numpy arrays is ...\n",
    "    \"\"\"\n",
    "    mels = [[]]\n",
    "    \n",
    "    for i, y in enumerate(ys):\n",
    "        mels[i].append(librosa.feature.mfcc(y[0], sr=sr, n_mfcc=n_mfcc, n_fft=N_FFT, hop_length=hop_size))\n",
    "        mels.append([])\n",
    "    return mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cost(costs, num_epochs):\n",
    "    print(len(costs))\n",
    "    x = numpy.arange(0, num_epochs, 1)\n",
    "    print(len(x))\n",
    "    print(num_epochs)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.plot(x, costs)\n",
    "    plt.show()\n",
    "\n",
    "def greedy_decoder(outs, all_labels):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    outputs=outs\n",
    "    string=[]\n",
    "    maximals, indices = outputs.max(1)\n",
    "    for i in indices:\n",
    "        string.append(all_labels[i])\n",
    "    itertools.groupby(string)\n",
    "    string=[k for k, g in itertools.groupby(string)]\n",
    "    output =[]\n",
    "    for s in string:\n",
    "        if s != \"-\":\n",
    "            output.append(s)\n",
    "    \n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "def WER(predicted, ground_truth):\n",
    "    arr=numpy.zeros([len(predicted) + 1, len(ground_truth) + 1])\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    while i < len(arr):\n",
    "        j = 0\n",
    "        \n",
    "        while j < len(arr[i]):\n",
    "            if i == 0:\n",
    "                arr[0][j] = j\n",
    "            elif j == 0:\n",
    "                arr[i][0] = i\n",
    "    \n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "        \n",
    "    i = 1\n",
    "    while i < len(arr):\n",
    "        \n",
    "        j = 1\n",
    "        while j < len(arr[i]):\n",
    "            if predicted[i - 1] == ground_truth[j - 1]:\n",
    "                arr[i][j] = arr[i - 1][j - 1]\n",
    "            else:\n",
    "                replace = arr[i-1][j-1] + 1\n",
    "                insert  = arr[i][j-1]   + 1\n",
    "                delete  = arr[i-1][j]   + 1\n",
    "                arr[i][j]=min(replace, insert, delete)\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "    \n",
    "    return arr[len(predicted)][len(ground_truth)]/len(predicted.split())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "* we open the samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"an4_dataset/train/\"#path to the dataset\n",
    "\n",
    "ys, srs = load_samples(path)\n",
    "labels = load_labels(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = \"an4_dataset/validation/\"\n",
    "\n",
    "ys_valid, srs = load_samples(path2)\n",
    "labels_valid = load_labels(path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "* loaded data is preprocessed\n",
    "* we perform stft using librosa\n",
    "* then we add melspectrogram\n",
    "* and MFCCs, all are prepared, but we can use each of them, so we get different kinds of features\n",
    "\n",
    "**Note**: For stft we have a window size, typically 512 or 256 and hop size. On each iteration we start at \n",
    "$$\n",
    "n_1 = N_f x H\n",
    "$$\n",
    "and we finish at\n",
    "$$\n",
    "n_2 = n_1 + M - 1\n",
    "$$\n",
    "\n",
    "https://dsp.stackexchange.com/questions/38491/time-position-in-stft-output\n",
    "\n",
    "H is a hop size (length) and M is a window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max=find_max(ys=ys)\n",
    "valid_max=find_max(ys=ys_valid)\n",
    "max_len= train_max if train_max>valid_max else valid_max\n",
    "\n",
    "ys_new = pad_signal(ys, max_len)\n",
    "ys_valid_new=pad_signal(ys_valid, max_len)\n",
    "\n",
    "ys_emphasized=pre_emphasize(ys_new, 0.97)\n",
    "ys_valid_emphasize=pre_emphasize(ys_valid_new, 0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 400 #window size\n",
    "window = 'hamming'\n",
    "hop_size = 160\n",
    "N_MFCC = 40\n",
    "\n",
    "#Ds=fourier_transform(ys=ys_emphasized, N_FFT=N_FFT, window=window, hop_size=hop_size)\n",
    "Ms=mfccs(ys=ys_emphasized, n_mfcc=N_MFCC, N_FFT=N_FFT, hop_size=hop_size)\n",
    "Ms_valid=mfccs(ys=ys_valid_emphasize, n_mfcc=N_MFCC, N_FFT=N_FFT, hop_size=hop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Here we plot mel spectrogram of one of the samples. Since this sample is pretty \n",
    "#long, we have something over the whole time period\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(Ms[1][0], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "Here we create a neural network, define loss function (CTCLoss in our case) and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool1d, Dropout2d, Conv1d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "641\n",
      "36\n",
      "641\n",
      "34\n",
      "641\n",
      "Net(\n",
      "  (conv_1): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv_dropout_1): Dropout2d(p=0.4)\n",
      "  (conv_2): Conv2d(32, 128, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv_dropout_2): Dropout2d(p=0.2)\n",
      "  (conv_3): Conv2d(128, 16, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv_dropout_3): Dropout2d(p=0.1)\n",
      "  (conv_4): Conv2d(16, 8, kernel_size=(1, 3), stride=(1, 1))\n",
      "  (conv_dropout_4): Dropout2d(p=0.05)\n",
      "  (l_1): Linear(in_features=256, out_features=200, bias=True)\n",
      "  (l_out): Linear(in_features=200, out_features=28, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyperameters of the model\n",
    "num_classes = 28\n",
    "channels = 1\n",
    "height = 641\n",
    "width = 40\n",
    "\n",
    "num_filters_conv1 = 32\n",
    "kernel_size_conv1 = (1,3) # [height, width]\n",
    "stride_conv1 = (1, 1) # [stride_height, stride_width]\n",
    "padding_conv1 = (0,0)\n",
    "dilation_conv1 = (1, 1)\n",
    "\n",
    "\n",
    "stride_pool1 = 2\n",
    "kernel_size_pool1 = 2\n",
    "padding_pool1 = 0\n",
    "dilation_pool1 = 1\n",
    "\n",
    "#convolutional layer\n",
    "num_filters_conv2 = 128\n",
    "kernel_size_conv2 = (1, 3) # [height, width]\n",
    "stride_conv2 = (1, 1) # [stride_height, stride_width]\n",
    "padding_conv2 = (0,0)\n",
    "dilation_conv2 = (1,1)\n",
    "\n",
    "stride_pool2 = 2\n",
    "kernel_size_pool2 = 2\n",
    "padding_pool2 = 0\n",
    "dilation_pool2 = 1\n",
    "\n",
    "#3rd convolutional layer\n",
    "num_filters_conv3 = 16\n",
    "kernel_size_conv3 = (1,3) # [height, width]\n",
    "stride_conv3 = (1,1) # [stride_height, stride_width]\n",
    "padding_conv3 = (0,0)\n",
    "dilation_conv3 = (1,1)\n",
    "\n",
    "\n",
    "stride_pool3 = 2\n",
    "kernel_size_pool3 = 2\n",
    "padding_pool3 = 0\n",
    "dilation_pool3 = 1\n",
    "\n",
    "#4th convolutional layer\n",
    "num_filters_conv4 = 8\n",
    "kernel_size_conv4 = (1,3) # [height, width]\n",
    "stride_conv4 = (1, 1) # [stride_height, stride_width]\n",
    "padding_conv4 = (0,0)\n",
    "dilation_conv4 = (1,1)\n",
    "\n",
    "batch_size=40\n",
    "num_l1 = 200\n",
    "dilation=1\n",
    "\n",
    "def compute_conv_dim(dim_size):\n",
    "    return int((dim_size - kernel_size_conv1 + 2 * padding_conv1) / stride_conv1 + 1)\n",
    "\n",
    "def compute_maxPool_dim(dim_size):\n",
    "    return int((dim_size - kernel_size_pool1 + 2 * padding_conv1) / stride_pool1 + 1)\n",
    "\n",
    "\n",
    "def compute_conv_dim_1d(L_in, kernel_in, padding_in = 0, dilation_in = 1, stride_in = 1):\n",
    "    return int((L_in + 2*padding_in - dilation_in*(kernel_in - 1) - 1)/stride_in + 1)\n",
    "\n",
    "def compute_conv_height_2d(H_in, kernel_size_height, padding_height=0, dilation_height=1, stride_height=1):\n",
    "    return int((H_in+2*padding_height-dilation_height*(kernel_size_height - 1) - 1)/stride_height + 1)\n",
    "\n",
    "def compute_conv_width_2d(W_in,  kernel_size_width, padding_width=0, dilation_width=1, stride_width=1):\n",
    "    return int((W_in+2*padding_width-dilation_width*(kernel_size_width-1) - 1)/stride_width + 1)\n",
    "\n",
    "def compute_pool_dim_1d(L_in, kernel_in, padding_in = 0, dilation_in = 1, stride_in = 1):\n",
    "    return int((L_in + 2*padding_in - dilation_in*(kernel_in - 1) - 1)/stride_in + 1)\n",
    "    \n",
    "# define network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #out_dim = (input_dim - filter_dim + 2 * padding) / stride + 1\n",
    "        self.conv_1 = Conv2d(in_channels=channels,\n",
    "                             out_channels=num_filters_conv1,\n",
    "                             kernel_size=kernel_size_conv1,\n",
    "                             stride=stride_conv1,\n",
    "                             padding=padding_conv1,\n",
    "                             dilation=dilation_conv1)\n",
    "        \n",
    "        self.conv_width_1=compute_conv_width_2d(W_in=width, kernel_size_width=kernel_size_conv1[1],\n",
    "                                                padding_width=padding_conv1[1], dilation_width=dilation_conv1[1],\n",
    "                                                stride_width=stride_conv1[1])\n",
    "        self.conv_height_1=compute_conv_height_2d(H_in=height, kernel_size_height=kernel_size_conv1[0],\n",
    "                                                  padding_height=padding_conv1[0], dilation_height=dilation_conv1[0],\n",
    "                                                  stride_height=stride_conv1[0])\n",
    "        \n",
    "        print(self.conv_width_1)\n",
    "        print(self.conv_height_1)\n",
    "        \n",
    "        self.conv_dropout_1=torch.nn.Dropout2d(p=0.4)\n",
    "        #self.conv_batchnorm_1=torch.nn.BatchNorm2d(num_filters_conv1)\n",
    "        \n",
    "        self.conv_2 = Conv2d(in_channels=num_filters_conv1,\n",
    "                             out_channels=num_filters_conv2,\n",
    "                             kernel_size=kernel_size_conv2,\n",
    "                             stride=stride_conv2,\n",
    "                             padding=padding_conv2,\n",
    "                             dilation=dilation_conv2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_width_2=compute_conv_width_2d(W_in=self.conv_width_1, kernel_size_width=kernel_size_conv2[1],\n",
    "                                                padding_width=padding_conv2[1], dilation_width=dilation_conv2[1],\n",
    "                                                stride_width=stride_conv2[1])\n",
    "        self.conv_height_2=compute_conv_height_2d(H_in=self.conv_height_1, kernel_size_height=kernel_size_conv2[0],\n",
    "                                                  padding_height=padding_conv2[0], dilation_height=dilation_conv2[0],\n",
    "                                                  stride_height=stride_conv2[0])\n",
    "        \n",
    "        print(self.conv_width_2)\n",
    "        print(self.conv_height_2)\n",
    "        \n",
    "        \n",
    "        self.conv_dropout_2=torch.nn.Dropout2d(p=0.2)\n",
    "        #self.conv_batchnorm_2=torch.nn.BatchNorm2d(num_filters_conv2)\n",
    "        \n",
    "        self.conv_3 = Conv2d(in_channels=num_filters_conv2,\n",
    "                             out_channels=num_filters_conv3,\n",
    "                             kernel_size=kernel_size_conv3,\n",
    "                             stride=stride_conv3,\n",
    "                             padding=padding_conv3,\n",
    "                             dilation=dilation_conv3)\n",
    "        \n",
    "        \n",
    "        self.conv_width_3=compute_conv_width_2d(W_in=self.conv_width_2, kernel_size_width=kernel_size_conv3[1],\n",
    "                                                padding_width=padding_conv3[1], dilation_width=dilation_conv3[1],\n",
    "                                                stride_width=stride_conv3[1])\n",
    "        self.conv_height_3=compute_conv_height_2d(H_in=self.conv_height_2, kernel_size_height=kernel_size_conv3[0],\n",
    "                                                  padding_height=padding_conv3[0], dilation_height=dilation_conv3[0],\n",
    "                                                  stride_height=stride_conv3[0])\n",
    "        print(self.conv_width_3)\n",
    "        print(self.conv_height_3)\n",
    "        \n",
    "        \n",
    "        self.conv_dropout_3=torch.nn.Dropout2d(p=0.1)\n",
    "        #self.conv_batchnorm_3=torch.nn.BatchNorm2d(num_filters_conv3)\n",
    "        \n",
    "        self.conv_4 = Conv2d(in_channels=num_filters_conv3,\n",
    "                             out_channels=num_filters_conv4,\n",
    "                             kernel_size=kernel_size_conv4,\n",
    "                             stride=stride_conv4,\n",
    "                             padding=padding_conv4,\n",
    "                             dilation=dilation_conv4)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_width_4=compute_conv_width_2d(W_in=self.conv_width_3, kernel_size_width=kernel_size_conv4[1],\n",
    "                                                padding_width=padding_conv4[1], dilation_width=dilation_conv4[1],\n",
    "                                                stride_width=stride_conv4[1])\n",
    "        self.conv_height_4=compute_conv_height_2d(H_in=self.conv_height_3, kernel_size_height=kernel_size_conv4[0],\n",
    "                                                  padding_height=padding_conv4[0], dilation_height=dilation_conv4[0],\n",
    "                                                  stride_height=stride_conv4[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv_dropout_4=torch.nn.Dropout2d(p=0.05)\n",
    "        #self.conv_batchnorm_4=torch.nn.BatchNorm2d(num_filters_conv4)\n",
    "        \n",
    "        self.l1_in_features = self.conv_width_4*num_filters_conv4\n",
    "        #self.l1_in_features = channels * height * width\n",
    "        \n",
    "        self.l_1 = Linear(in_features=self.l1_in_features, \n",
    "                          out_features=num_l1,\n",
    "                          bias=True)\n",
    "        self.l_out = Linear(in_features=num_l1, \n",
    "                            out_features=num_classes,\n",
    "                            bias=False)\n",
    "    \n",
    "    def forward(self, x): # x.size() = [batch, channel, height, width]\n",
    "        #print(x.shape)\n",
    "        #(641, 1, 40)\n",
    "        x = relu(self.conv_1(x))\n",
    "        x = self.conv_dropout_1(x)\n",
    "        #x = self.conv_batchnorm_1(x)\n",
    "        #torch.Size([641, 16, 38])\n",
    "        #x = self.maxPool_1(x)\n",
    "        #([641, 16, 19])\n",
    "        x = relu(self.conv_2(x))\n",
    "        x = self.conv_dropout_2(x)\n",
    "        #x = self.conv_batchnorm_2(x)\n",
    "        #print(x.shape)\n",
    "        #x = self.maxPool_2(x)\n",
    "        \n",
    "        x = relu(self.conv_3(x))\n",
    "        x = self.conv_dropout_3(x)\n",
    "        #x = self.conv_batchnorm_3(x)\n",
    "        \n",
    "        x = relu(self.conv_4(x))\n",
    "        x = self.conv_dropout_4(x)\n",
    "        #x = self.conv_batchnorm_4(x)\n",
    "        \n",
    "        #x = self.maxPool_3(x)\n",
    "        #print(x.shape)\n",
    "        #x = x.view(1,  641, self.l1_in_features)\n",
    "        x.permute(0,2,1,3)\n",
    "        x = x.view(batch_size, self.conv_height_4, self.l1_in_features)\n",
    "        x = relu(self.l_1(x))\n",
    "        \n",
    "        # torch.Tensor.view: http://pytorch.org/docs/master/tensors.html?highlight=view#torch.Tensor.view\n",
    "        #   Returns a new tensor with the same data as the self tensor,\n",
    "        #   but of a different size.\n",
    "        # the size -1 is inferred from other dimensions \n",
    "        #print(x.shape)#NCHW to HCNW\n",
    "        #x=x.permute(0, 2, 1, 3)\n",
    "        #print(x.shape)\n",
    "        #x=x.contiguous()\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = self.dropout(relu(self.l_1(x)))\n",
    "        #x = relu(self.l_1(x))\n",
    "        #print(x.shape)\n",
    "        return torch.nn.functional.log_softmax(self.l_out(x), dim=1)\n",
    "        #return self.l_out(x)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CTCLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "\n",
    "* In here we prepare the lables - characters A - Z, space and blank character\n",
    "* number of samples used for training\n",
    "* number of epochs for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ' ']\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "valid_epochs=10\n",
    "num_samples = 500\n",
    "all_labels= [\n",
    "    \"-\",\n",
    "    \"A\",\n",
    "    \"B\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "    \"E\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"H\",\n",
    "    \"I\",\n",
    "    \"J\",\n",
    "    \"K\",\n",
    "    \"L\",\n",
    "    \"M\",\n",
    "    \"N\",\n",
    "    \"O\",\n",
    "    \"P\",\n",
    "    \"Q\",\n",
    "    \"R\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"U\",\n",
    "    \"V\",\n",
    "    \"W\",\n",
    "    \"X\",\n",
    "    \"Y\",\n",
    "    \"Z\",\n",
    "    \" \",\n",
    "]\n",
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "\n",
    "* In here we train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "costs=[]\n",
    "epoch=0\n",
    "while epoch < num_epochs:\n",
    "    for i in range(int(num_samples/batch_size)):\n",
    "        net.train()\n",
    "\n",
    "        sample = numpy.empty([batch_size,1, 641, 40])\n",
    "        \n",
    "        ground_truth_sizes = torch.empty(batch_size)\n",
    "        probs_sizes = torch.empty(batch_size)\n",
    "        \n",
    "        ground_truth_string_int = []\n",
    "        avg_cost=0\n",
    "        for j in range(batch_size):\n",
    "            samp = numpy.asarray(Ms[i * batch_size + j][0], dtype=numpy.float32).T\n",
    "            sample[j][0] = samp\n",
    "            \n",
    "            string = ''.join(labels[i * batch_size + j])\n",
    "\n",
    "            ground_truth_sizes[j] = len(string)\n",
    "            probs_sizes[j] = 641\n",
    "\n",
    "            for character in string:\n",
    "                if(character == \" \"):\n",
    "                    number = 27\n",
    "                else:\n",
    "                    number = ord(character) - 64\n",
    "                ground_truth_string_int.append(number)\n",
    "        #print(sample.shape)\n",
    "        \n",
    "        input_sample=torch.from_numpy(sample)\n",
    "        \n",
    "        \n",
    "        #print(input_sample.shape)\n",
    "        #print(\"Len of truth: \" + str(len(ground_truth_string_int)))\n",
    "        #print(\"sum of truths: \" + str(sum(ground_truth_sizes)))\n",
    "\n",
    "        ground_truth = torch.IntTensor(ground_truth_string_int)\n",
    "        #print(\"going into network.\")\n",
    "        #print(input_sample)\n",
    "        out = net(Variable(input_sample).float())\n",
    "\n",
    "        \n",
    "        #greedy_decoder(out[0], all_labels)\n",
    "        \n",
    "        #print(\"out:\")\n",
    "        #print(out.shape)\n",
    "        \n",
    "        #print(\"probs sizes: \" + str(probs_sizes))\n",
    "\n",
    "        #run the criterion\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #print(ground_truth.shape)\n",
    "        #input must be in shape seq_length x batch size x outputs -> 641 x 1 x 28/27 (depends if we use spaces or not)\n",
    "        cost=criterion(out.transpose(0,1), torch.tensor(ground_truth_string_int).int(), probs_sizes.int(), ground_truth_sizes.int())\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        #print(cost)\n",
    "        avg_cost = avg_cost+cost.item()/batch_size\n",
    "        \n",
    "    #print(avg_cost)\n",
    "    avg_cost=avg_cost\n",
    "    epoch = epoch + 1\n",
    "    costs.append(avg_cost)\n",
    "    \n",
    "    #plots the average cost\n",
    "    if(epoch%2 == 0 and epoch > 0):\n",
    "        print(\"Number of epochs: \"  + str(epoch))\n",
    "        display_cost(costs, epoch)\n",
    "    \n",
    "    error_rates=[]\n",
    "    #evaluation not really implemented yet.    \n",
    "    if(epoch%valid_epochs == 0 and epoch > 0):\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            indices = [0]*batch_size\n",
    "            \n",
    "            for j in range(batch_size):\n",
    "                indices[j] = random.randint(0, len(Ms_valid) - 1)\n",
    "            print(indices)\n",
    "            \n",
    "            avg_error_rate = 0\n",
    "            for j in range(batch_size):\n",
    "                sample = numpy.empty([batch_size,1, 641, 40])\n",
    "                sample[0][0] = Ms_valid[j][0].T\n",
    "\n",
    "\n",
    "\n",
    "                out = net(Variable(torch.from_numpy(sample).float()))\n",
    "\n",
    "                ground_truth = ''.join(labels_valid[j])\n",
    "                predicted = ''.join(greedy_decoder(out[0], all_labels))\n",
    "                print(\"Predicted: \" + predicted)\n",
    "                print(\"Ground truth: \" + ground_truth)\n",
    "                wer = WER(predicted, ground_truth)\n",
    "                print(\"WER: \")\n",
    "                print(wer)\n",
    "                avg_error_rate = avg_error_rate + wer\n",
    "\n",
    "            avg_error_rate/5\n",
    "            error_rates.append(avg_error_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', ' ', 'N', ' ', 'N', 'O', ' ', 'N', ' ', 'Z', 'U', ' ', 'N', ' ', 'O', 'E', 'N', ' ', 'N', ' ', 'N', 'O']\n",
      "[19, 5, 22, 5, 14, 27, 6, 15, 21, 18, 27, 15, 14, 5, 27, 15, 8, 27, 6, 9, 22, 5, 27, 14, 9, 14, 5, 27, 20, 23, 15]\n",
      "Cost: \n",
      "169.950057983\n",
      "169.950057983\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [32, 1, 1, 3], but got input of size [641, 1, 40] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-8b6e7ff9de08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/miniconda3/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-6501e77aa2c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m#(641, 1, 40)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dropout_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_batchnorm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/miniconda3/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/karol/miniconda3/lib/python2.7/site-packages/torch/nn/modules/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 1, 1, 3], but got input of size [641, 1, 40] instead"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "costs=[]\n",
    "while i < num_epochs:\n",
    "    j=0\n",
    "    \n",
    "    net.train()\n",
    "    avg_cost = 0\n",
    "    while j < num_samples:\n",
    "        #here we select a sample Ms is in format [number of samples][1][sequence_length][num_features]\n",
    "        sample = numpy.empty([1,1, 641, 40])\n",
    "        sample[0][0] = Ms[j][0].T\n",
    "        sample_1 = sample[0].reshape((641,1, 40))\n",
    "        \n",
    "        #output from the NN\n",
    "        out = net(Variable(torch.from_numpy(sample).float()))\n",
    "        maximal, indices = out[0].max(1)\n",
    "        \n",
    "            \n",
    "        \n",
    "        #changes string to numbers - classes are 28 and class 0 - 25 should be A-Z, 26 is space and 27 blank\n",
    "        string = ''.join(labels[j])\n",
    "        ground_truth_string_int = []\n",
    "        for character in string:\n",
    "            if(character == \" \"):\n",
    "                number = 27\n",
    "            else:\n",
    "                number = ord(character) - 64\n",
    "            ground_truth_string_int.append(number)\n",
    "        \n",
    "        if(j%20 == 0 and i%5 == 0):\n",
    "            greedy_decoder(out[0], all_labels)\n",
    "            print(ground_truth_string_int)\n",
    "        #construct ground truth tensor\n",
    "        ground_truth = torch.IntTensor(ground_truth_string_int)\n",
    "\n",
    "        \n",
    "        #length of the ground truth sample\n",
    "        ground_truth_sizes = torch.IntTensor([len(ground_truth)])\n",
    "        \n",
    "        \n",
    "        #length of sequence - 641 in our case\n",
    "        probs_sizes = torch.IntTensor([out.shape[1]])\n",
    "        \n",
    "        \n",
    "        #run the criterion\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #input must be in shape seq_length x batch size x outputs -> 641 x 1 x 28/27 (depends if we use spaces or not)\n",
    "        cost=criterion(out.transpose(0,1).contiguous(), ground_truth, probs_sizes, ground_truth_sizes)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        #we try to display our current cost\n",
    "        if (i%1==0):\n",
    "            print(\"Cost: \")\n",
    "            print(cost.item())\n",
    "            beam_decoder = CTCBeamDecoder(all_labels, blank_id=27)\n",
    "            beam_res, beam_scores, timesteps, sequence_lens = beam_decoder.decode(probs=out, seq_lens=ground_truth_sizes)\n",
    "            for j, beam in enumerate(beam_res[0]):\n",
    "                output_string = ''.join([all_labels[x] for x in beam[0:sequence_lens[0][j]]])\n",
    "                #print(output_string) #uncomment this line to display the 'result'\n",
    "        j = j + 1\n",
    "        avg_cost = avg_cost + cost.item()\n",
    "        print(avg_cost)\n",
    "    avg_cost = avg_cost / num_samples\n",
    "    costs.append(avg_cost)\n",
    "    \n",
    "    \n",
    "    #plots the average cost\n",
    "    if(i%2 == 0 and i > 0):\n",
    "        display_cost(costs, i)\n",
    "        \n",
    "    net.eval()\n",
    "    #evaluation not really implemented yet.    \n",
    "    if(i%valid_epochs == 0):\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            sample = numpy.empty([1,1, 641, 40])\n",
    "            sample[0][0] = Ms[0][0].T\n",
    "            sample_1 = sample[0].reshape(641, 1, 40)\n",
    "\n",
    "\n",
    "\n",
    "            out = net(Variable(torch.from_numpy(sample_1).float()))\n",
    "            \n",
    "            string = ''.join(labels[0])\n",
    "            output = []\n",
    "            for character in string:\n",
    "                if(character == \" \"):\n",
    "                    number = 26\n",
    "                else:\n",
    "                    number = ord(character) - 65\n",
    "                output.append(number)\n",
    "\n",
    "            labels_crit = torch.IntTensor(output)\n",
    "\n",
    "            label_sizes = torch.IntTensor([len(labels_crit)])\n",
    "            beam_decoder = CTCBeamDecoder(all_labels, blank_id=27)\n",
    "            beam_res, beam_scores, timesteps, sequence_lens = beam_decoder.decode(probs=out, seq_lens=label_sizes)\n",
    "\n",
    "\n",
    "            for j, beam in enumerate(beam_res[0]):\n",
    "                output_string = ''.join([all_labels[x] for x in beam[0:sequence_lens[0][j]]])\n",
    "                #print(output_string)\n",
    "            #print(output_string)\n",
    "            print(labels[0])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Up until this point we used various different libraries.\n",
    "\n",
    "* For CTC cost we are using a warp-ctc function created by BAIDU which was recommended here: https://distill.pub/2017/ctc/\n",
    "* It was also used in DeepSpeech: https://github.com/SeanNaren/deepspeech.pytorch - we use different architecture and many things are different, since warp-ctc does not contain much documentation, we had to check out the implementation. In the end this one was only useful to search for the libraries.\n",
    "\n",
    "* Libraries we used:\n",
    "\n",
    "  * warp-ctc pytorch binding - to know how to use this one, we had to play with the unit tests, since the library hardly contains any documentation.\n",
    "  \n",
    "  https://github.com/SeanNaren/warp-ctc\n",
    "  \n",
    "  * ctcdecode - for beamsearch to construct the string in the evaluation. We still have problem to understand how to build it properly though.\n",
    "  \n",
    "  https://github.com/githubharald/CTCDecoder\n",
    "  \n",
    "  * Both of the libraries lack much documentation are difficult to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Ms[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
