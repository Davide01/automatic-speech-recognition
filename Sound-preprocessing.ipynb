{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /home/karol/miniconda3/lib/python2.7/site-packages (0.6.2)\n",
      "Requirement already satisfied: numba>=0.38.0 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (0.40.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/karol/.local/lib/python2.7/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: joblib>=0.12 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /home/karol/.local/lib/python2.7/site-packages (from librosa) (1.14.5)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (0.19.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (2.1.6)\n",
      "Requirement already satisfied: six>=1.3 in /home/karol/.local/lib/python2.7/site-packages (from librosa) (1.11.0)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (0.2.1)\n",
      "Requirement already satisfied: funcsigs in /home/karol/miniconda3/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (1.0.2)\n",
      "Requirement already satisfied: singledispatch in /home/karol/miniconda3/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (3.4.0.3)\n",
      "Requirement already satisfied: llvmlite>=0.25.0dev0 in /home/karol/miniconda3/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (0.25.0)\n",
      "Requirement already satisfied: enum34 in /home/karol/miniconda3/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (1.1.6)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import torch\n",
    "from warpctc_pytorch import CTCLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for file manipulation\n",
    "def load_samples(file_path):\n",
    "    ys, srs = [[]],[[]]\n",
    "    i = 0\n",
    "    #loads .wav files\n",
    "    for filename in os.listdir(file_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            y, sr = librosa.load(path+filename, sr=16000)\n",
    "            ys[i].append(y)\n",
    "            srs[i].append(sr)\n",
    "            i = i + 1\n",
    "            ys.append([])\n",
    "            srs.append([])  \n",
    "    ys = ys[0: len(ys) - 1]\n",
    "    srs = srs[0: len(srs) - 1]\n",
    "    return (ys, srs)\n",
    "def load_labels(file_path):\n",
    "    i = 0\n",
    "    labels = [[]]\n",
    "    \n",
    "    for filename in os.listdir(file_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file = open(file_path+filename, \"r\") \n",
    "            labels[i].append(file.read())\n",
    "            labels.append([])\n",
    "            i = i + 1\n",
    "            \n",
    "    labels=labels[0: len(labels) - 1]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for feature extraction\n",
    "def find_max(ys):\n",
    "    maximum =0\n",
    "    for y1 in ys:\n",
    "        for y2 in y1:\n",
    "            dim = y2.shape[0]\n",
    "            if dim > maximum:\n",
    "                maximum = dim\n",
    "    return maximum\n",
    "\n",
    "def pad_signal(ys):\n",
    "    max_length = find_max(ys)\n",
    "    \n",
    "    ys_new = ys\n",
    "    for i, y1 in enumerate(ys_new):\n",
    "        for j, y2 in enumerate(y1):\n",
    "            if len(y2) < max_length:\n",
    "                z = numpy.zeros((max_length - len(y2)))\n",
    "                pad_signal = numpy.append(y2, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "                ys_new[i][j] = pad_signal\n",
    "    return ys_new\n",
    "def pre_emphasize(ys, pre_emphasis):\n",
    "    for i, y in enumerate(ys):\n",
    "        signal=y[0]\n",
    "        y[0] = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "    return ys\n",
    "def fourier_transform(ys, N_FFT=512, window='hamming', hop_size=256):\n",
    "\n",
    "    Ds = [[]]\n",
    "\n",
    "    for i, y in enumerate(ys):\n",
    "        Ds[i].append(librosa.core.stft(y=y[0], n_fft=N_FFT, window=window, hop_length=hop_size))\n",
    "        Ds.append([])\n",
    "    return Ds\n",
    "\n",
    "def mfccs(ys, N_FFT=512, sr=16000, n_mfcc=40, hop_size=256):\n",
    "    mels = [[]]\n",
    "    \n",
    "    for i, y in enumerate(ys):\n",
    "        mels[i].append(librosa.feature.mfcc(y[0], sr=sr, n_mfcc=n_mfcc, n_fft=N_FFT, hop_length=hop_size))\n",
    "        mels.append([])\n",
    "    return mels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "* we open the samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"an4_dataset/train/\"#path to the dataset\n",
    "\n",
    "ys, srs = load_samples(path)\n",
    "labels = load_labels(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "* loaded data is preprocessed\n",
    "* we perform stft using librosa\n",
    "* then we add melspectrogram\n",
    "* and MFCCs, all are prepared, but we can use each of them, so we get different kinds of features\n",
    "\n",
    "**Note**: For stft we have a window size, typically 512 or 256 and hop size. On each iteration we start at \n",
    "$$\n",
    "n_1 = N_f x H\n",
    "$$\n",
    "and we finish at\n",
    "$$\n",
    "n_2 = n_1 + M - 1\n",
    "$$\n",
    "\n",
    "https://dsp.stackexchange.com/questions/38491/time-position-in-stft-output\n",
    "\n",
    "H is a hop size (length) and M is a window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_new = pad_signal(ys)\n",
    "\n",
    "ys_emphasized=pre_emphasize(ys_new, 0.97)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 400 #window size\n",
    "window = 'hamming'\n",
    "hop_size = 160\n",
    "N_MFCC = 40\n",
    "\n",
    "Ds=fourier_transform(ys=ys_emphasized, N_FFT=N_FFT, window=window, hop_size=hop_size)\n",
    "Ms=mfccs(ys=ys_emphasized, n_mfcc=N_MFCC, N_FFT=N_FFT, hop_size=hop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d, Conv1d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv_1): Conv2d(1, 16, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (l_1): Linear(in_features=592, out_features=100, bias=True)\n",
      "  (l_out): Linear(in_features=100, out_features=27, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyperameters of the model\n",
    "num_classes = 27\n",
    "channels = 1\n",
    "height = 641\n",
    "width = 40\n",
    "num_filters_conv1 = 16\n",
    "kernel_size_conv1 = 4 # [height, width]\n",
    "stride_conv1 = 1 # [stride_height, stride_width]\n",
    "kernel_size_pool1 = 1\n",
    "stride_pool1 = 1\n",
    "num_l1 = 100\n",
    "padding_conv1 = 0\n",
    "dilation=1\n",
    "\n",
    "def compute_conv_dim(dim_size):\n",
    "    return int((dim_size - kernel_size_conv1 + 2 * padding_conv1) / stride_conv1 + 1)\n",
    "\n",
    "def compute_maxPool_dim(dim_size):\n",
    "    return int((dim_size - kernel_size_pool1 + 2 * padding_conv1) / stride_pool1 + 1)\n",
    "\n",
    "def comput_conv_1d_dim(dim_size):\n",
    "    return int((dim_size+2*padding_conv1-dilation*(kernel_size_conv1-1) - 1)/stride_conv1 + 1)\n",
    "    \n",
    "def comput_maxPool_dim(dim_size):\n",
    "    return int((dim_size+2*padding_conv1-dilation*(kernel_size_pool1-1) - 1)/stride_pool1 + 1)\n",
    "\n",
    "# define network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #out_dim = (input_dim - filter_dim + 2 * padding) / stride + 1\n",
    "        self.conv_1 = Conv2d(in_channels=channels,\n",
    "                             out_channels=num_filters_conv1,\n",
    "                             kernel_size=kernel_size_conv1,\n",
    "                             stride=stride_conv1)\n",
    "        \n",
    "       # self.maxPool_1 = MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.conv_out_height = compute_conv_dim(height)\n",
    "        self.conv_out_width = compute_conv_dim(width)\n",
    "      #  self.conv_out_height = compute_maxPool_dim(self.conv_out_height)\n",
    "      #  self.conv_out_width = compute_maxPool_dim(self.conv_out_width)\n",
    "        \n",
    "        # add dropout to network\n",
    "        #self.dropout = Dropout2d(p=0.5)\n",
    "        self.l1_in_features = num_filters_conv1*self.conv_out_width\n",
    "        #self.l1_in_features = channels * height * width\n",
    "        \n",
    "        self.l_1 = Linear(in_features=self.l1_in_features, \n",
    "                          out_features=num_l1,\n",
    "                          bias=True)\n",
    "        self.l_out = Linear(in_features=num_l1, \n",
    "                            out_features=num_classes,\n",
    "                            bias=False)\n",
    "    \n",
    "    def forward(self, x): # x.size() = [batch, channel, height, width]\n",
    "        x = relu(self.conv_1(x))\n",
    "        #x = self.maxPool_1(x)\n",
    "        # torch.Tensor.view: http://pytorch.org/docs/master/tensors.html?highlight=view#torch.Tensor.view\n",
    "        #   Returns a new tensor with the same data as the self tensor,\n",
    "        #   but of a different size.\n",
    "        # the size -1 is inferred from other dimensions \n",
    "        #print(x.shape)#NCHW to HCNW\n",
    "        x=x.permute(0, 2, 1, 3)\n",
    "        #print(x.shape)\n",
    "        x=x.contiguous()\n",
    "        x = x.view(1, self.conv_out_height, self.l1_in_features)\n",
    "        #print(x.shape)\n",
    "        #x = self.dropout(relu(self.l_1(x)))\n",
    "        x = relu(self.l_1(x))\n",
    "        #print(x.shape)\n",
    "        return softmax(self.l_out(x), dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CTCLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949\n",
      "1\n",
      "641\n"
     ]
    }
   ],
   "source": [
    "print(len(Ms))\n",
    "print(len(Ms[0]))\n",
    "print(len(Ms[0][0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = numpy.empty([1,1, 641, 40])\n",
    "sample[0][0] = Ms[0][0].T\n",
    "#sample=numpy.empty([641, 1, 40])\n",
    "#for i, row in enumerate(Ms[0][0]):\n",
    "#    sample[i] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object parameters at 0x7fb1c0f7a730>\n",
      "torch.Size([1, 638, 27])\n",
      "[18, 4, 21, 4, 13, 5, 14, 20, 17, 14, 13, 4, 14, 7, 5, 8, 21, 4, 13, 8, 13, 4, 19, 22, 14]\n",
      "torch.Size([638, 1, 27])\n"
     ]
    }
   ],
   "source": [
    "print(net.parameters())\n",
    "#print(batch.shape)\n",
    "out = net(Variable(torch.from_numpy(sample).float()))\n",
    "print(out.shape)\n",
    "string = ''.join(labels[0])\n",
    "string = string.strip()\n",
    "string = string.replace(\" \", \"\")\n",
    "\n",
    "output = []\n",
    "for character in string:\n",
    "    number = ord(character) - 65\n",
    "    output.append(number)\n",
    "print output\n",
    "\n",
    "labels_crit = torch.IntTensor(output)\n",
    "\n",
    "label_sizes = torch.IntTensor([len(labels_crit)])\n",
    "probs_sizes = torch.IntTensor([out.shape[1]])\n",
    "\n",
    "print(out.transpose(0,1).contiguous().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=criterion(out.transpose(0,1).contiguous(), labels_crit, probs_sizes, label_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1928.3000], grad_fn=<_CTCBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: \n",
      "tensor([1928.3000], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "0\n",
      "Cost: \n",
      "tensor([1977.4470], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "300\n",
      "Cost: \n",
      "tensor([1928.2482], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "0\n",
      "Cost: \n",
      "tensor([1977.4022], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "300\n",
      "Cost: \n",
      "tensor([1928.2178], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "0\n",
      "Cost: \n",
      "tensor([1977.4944], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "300\n",
      "Cost: \n",
      "tensor([1928.3505], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "0\n",
      "Cost: \n",
      "tensor([1977.3250], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "300\n",
      "Cost: \n",
      "tensor([1928.2369], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "0\n",
      "Cost: \n",
      "tensor([1977.5021], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "num_epochs = 5\n",
    "\n",
    "j = 0\n",
    "\n",
    "while i < num_epochs:\n",
    "    j=0\n",
    "    \n",
    "    net.train()\n",
    "    while j < 600:\n",
    "        sample = numpy.empty([1,1, 641, 40])\n",
    "        sample[0][0] = Ms[j][0].T\n",
    "        out = net(Variable(torch.from_numpy(sample).float()))\n",
    "        string = ''.join(labels[j])\n",
    "        string = string.strip()\n",
    "        string = string.replace(\" \", \"\")\n",
    "        #print(string)\n",
    "        output = []\n",
    "        for character in string:\n",
    "            number = ord(character) - 65\n",
    "            output.append(number)\n",
    "        #print output\n",
    "\n",
    "        labels_crit = torch.IntTensor(output)\n",
    "\n",
    "        label_sizes = torch.IntTensor([len(labels_crit)])\n",
    "        probs_sizes = torch.IntTensor([out.shape[1]])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        #print(out.shape)\n",
    "        probs.requires_grad_(True)\n",
    "        #print(probs.grad())\n",
    "        #labels_crit.requires_grad_(True)\n",
    "        \n",
    "        cost=criterion(out.transpose(0,1).contiguous(), labels_crit, probs_sizes, label_sizes)\n",
    "        cost.backward()\n",
    "        #print(probs.grad())\n",
    "        if (j%300==0):\n",
    "            print(\"Cost: \")\n",
    "            print(cost)\n",
    "            print(i)\n",
    "            print(j)\n",
    "        j = j + 1\n",
    "        optimizer.step()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = load_labels(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
