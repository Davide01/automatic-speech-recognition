{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /home/karol/miniconda3/lib/python2.7/site-packages (0.6.2)\n",
      "Requirement already satisfied: numba>=0.38.0 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (0.40.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/karol/.local/lib/python2.7/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: joblib>=0.12 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.8.0 in /home/karol/.local/lib/python2.7/site-packages (from librosa) (1.14.5)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (0.19.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (2.1.6)\n",
      "Requirement already satisfied: six>=1.3 in /home/karol/.local/lib/python2.7/site-packages (from librosa) (1.11.0)\n",
      "Requirement already satisfied: resampy>=0.2.0 in /home/karol/miniconda3/lib/python2.7/site-packages (from librosa) (0.2.1)\n",
      "Requirement already satisfied: funcsigs in /home/karol/miniconda3/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (1.0.2)\n",
      "Requirement already satisfied: singledispatch in /home/karol/miniconda3/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (3.4.0.3)\n",
      "Requirement already satisfied: llvmlite>=0.25.0dev0 in /home/karol/miniconda3/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (0.25.0)\n",
      "Requirement already satisfied: enum34 in /home/karol/miniconda3/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (1.1.6)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import os\n",
    "import torch\n",
    "from warpctc_pytorch import CTCLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for file manipulation\n",
    "def load_samples(file_path):\n",
    "    ys, srs = [[]],[[]]\n",
    "    i = 0\n",
    "    #loads .wav files\n",
    "    for filename in os.listdir(file_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            y, sr = librosa.load(path+filename, sr=16000)\n",
    "            ys[i].append(y)\n",
    "            srs[i].append(sr)\n",
    "            i = i + 1\n",
    "            ys.append([])\n",
    "            srs.append([])  \n",
    "    ys = ys[0: len(ys) - 1]\n",
    "    srs = srs[0: len(srs) - 1]\n",
    "    return (ys, srs)\n",
    "def load_labels(file_path):\n",
    "    i = 0\n",
    "    labels = [[]]\n",
    "    \n",
    "    for filename in os.listdir(file_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file = open(file_path+filename, \"r\") \n",
    "            labels[i].append(file.read())\n",
    "            labels.append([])\n",
    "            i = i + 1\n",
    "            \n",
    "    labels=labels[0: len(labels) - 1]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for feature extraction\n",
    "def find_max(ys):\n",
    "    maximum =0\n",
    "    for y1 in ys:\n",
    "        for y2 in y1:\n",
    "            dim = y2.shape[0]\n",
    "            if dim > maximum:\n",
    "                maximum = dim\n",
    "    return maximum\n",
    "\n",
    "def pad_signal(ys):\n",
    "    max_length = find_max(ys)\n",
    "    \n",
    "    ys_new = ys\n",
    "    for i, y1 in enumerate(ys_new):\n",
    "        for j, y2 in enumerate(y1):\n",
    "            if len(y2) < max_length:\n",
    "                z = numpy.zeros((max_length - len(y2)))\n",
    "                pad_signal = numpy.append(y2, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\n",
    "                ys_new[i][j] = pad_signal\n",
    "    return ys_new\n",
    "def pre_emphasize(ys, pre_emphasis):\n",
    "    for i, y in enumerate(ys):\n",
    "        signal=y[0]\n",
    "        y[0] = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "    return ys\n",
    "def fourier_transform(ys, N_FFT=512, window='hamming', hop_size=256):\n",
    "\n",
    "    Ds = [[]]\n",
    "\n",
    "    for i, y in enumerate(ys):\n",
    "        Ds[i].append(librosa.core.stft(y=y[0], n_fft=N_FFT, window=window, hop_length=hop_size))\n",
    "        Ds.append([])\n",
    "    return Ds\n",
    "\n",
    "def mfccs(ys, N_FFT=512, sr=16000, n_mfcc=40, hop_size=256):\n",
    "    mels = [[]]\n",
    "    \n",
    "    for i, y in enumerate(ys):\n",
    "        mels[i].append(librosa.feature.mfcc(y[0], sr=sr, n_mfcc=n_mfcc, n_fft=N_FFT, hop_length=hop_size))\n",
    "        mels.append([])\n",
    "    return mels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "* we open the samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"an4_dataset/train/\"#path to the dataset\n",
    "\n",
    "ys, srs = load_samples(path)\n",
    "labels = load_labels(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "* loaded data is preprocessed\n",
    "* we perform stft using librosa\n",
    "* then we add melspectrogram\n",
    "* and MFCCs, all are prepared, but we can use each of them, so we get different kinds of features\n",
    "\n",
    "**Note**: For stft we have a window size, typically 512 or 256 and hop size. On each iteration we start at \n",
    "$$\n",
    "n_1 = N_f x H\n",
    "$$\n",
    "and we finish at\n",
    "$$\n",
    "n_2 = n_1 + M - 1\n",
    "$$\n",
    "\n",
    "https://dsp.stackexchange.com/questions/38491/time-position-in-stft-output\n",
    "\n",
    "H is a hop size (length) and M is a window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_new = pad_signal(ys)\n",
    "\n",
    "ys_emphasized=pre_emphasize(ys_new, 0.97)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 400 #window size\n",
    "window = 'hamming'\n",
    "hop_size = 160\n",
    "N_MFCC = 40\n",
    "\n",
    "Ds=fourier_transform(ys=ys_emphasized, N_FFT=N_FFT, window=window, hop_size=hop_size)\n",
    "Ms=mfccs(ys=ys_emphasized, n_mfcc=N_MFCC, N_FFT=N_FFT, hop_size=hop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv_1): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (l_1): Linear(in_features=640, out_features=100, bias=True)\n",
      "  (l_out): Linear(in_features=100, out_features=27, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyperameters of the model\n",
    "num_classes = 27\n",
    "channels = 1\n",
    "height = 1\n",
    "width = 40\n",
    "num_filters_conv1 = 16\n",
    "kernel_size_conv1 = 1 # [height, width]\n",
    "stride_conv1 = 1 # [stride_height, stride_width]\n",
    "kernel_size_pool1 = 1\n",
    "stride_pool1 = 1\n",
    "num_l1 = 100\n",
    "padding_conv1 = 0\n",
    "   \n",
    "def compute_conv_dim(dim_size):\n",
    "    return int((dim_size - kernel_size_conv1 + 2 * padding_conv1) / stride_conv1 + 1)\n",
    "\n",
    "def compute_maxPool_dim(dim_size):\n",
    "    return int((dim_size - kernel_size_pool1 + 2 * padding_conv1) / stride_pool1 + 1)\n",
    "\n",
    "# define network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #out_dim = (input_dim - filter_dim + 2 * padding) / stride + 1\n",
    "        self.conv_1 = Conv2d(in_channels=channels,\n",
    "                             out_channels=num_filters_conv1,\n",
    "                             kernel_size=kernel_size_conv1,\n",
    "                             stride=stride_conv1)\n",
    "        \n",
    "       # self.maxPool_1 = MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.conv_out_height = compute_conv_dim(height)\n",
    "        self.conv_out_width = compute_conv_dim(width)\n",
    "      #  self.conv_out_height = compute_maxPool_dim(self.conv_out_height)\n",
    "      #  self.conv_out_width = compute_maxPool_dim(self.conv_out_width)\n",
    "        \n",
    "        # add dropout to network\n",
    "        #self.dropout = Dropout2d(p=0.5)\n",
    "        self.l1_in_features = num_filters_conv1 * self.conv_out_height * self.conv_out_width\n",
    "        #self.l1_in_features = channels * height * width\n",
    "        \n",
    "        self.l_1 = Linear(in_features=self.l1_in_features, \n",
    "                          out_features=num_l1,\n",
    "                          bias=True)\n",
    "        self.l_out = Linear(in_features=num_l1, \n",
    "                            out_features=num_classes,\n",
    "                            bias=False)\n",
    "    \n",
    "    def forward(self, x): # x.size() = [batch, channel, height, width]\n",
    "        x = relu(self.conv_1(x))\n",
    "        #x = self.maxPool_1(x)\n",
    "        # torch.Tensor.view: http://pytorch.org/docs/master/tensors.html?highlight=view#torch.Tensor.view\n",
    "        #   Returns a new tensor with the same data as the self tensor,\n",
    "        #   but of a different size.\n",
    "        # the size -1 is inferred from other dimensions \n",
    "        x = x.view(-1, self.l1_in_features)\n",
    "        #x = self.dropout(relu(self.l_1(x)))\n",
    "        x = relu(self.l_1(x))\n",
    "        return softmax(self.l_out(x), dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CTCLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949\n",
      "1\n",
      "641\n"
     ]
    }
   ],
   "source": [
    "print(len(Ms))\n",
    "print(len(Ms[0]))\n",
    "print(len(Ms[0][0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641\n",
      "(641, 1, 1, 40)\n"
     ]
    }
   ],
   "source": [
    "batch = []\n",
    "\n",
    "index = 0\n",
    "print(len(Ms[0][0].T))\n",
    "    \n",
    "for index in Ms[0][0].T:\n",
    "    x = numpy.array([[index]])\n",
    "    batch.append(x)\n",
    "         \n",
    "batch = numpy.stack(batch, axis=0)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 4, 21, 4, 13, 5, 14, 20, 17, 14, 13, 4, 14, 7, 5, 8, 21, 4, 13, 8, 13, 4, 19, 22, 14]\n",
      "[[[1.18548087e-19 3.69547226e-10 9.28313237e-22 ... 1.17465248e-15\n",
      "   1.58453426e-19 1.30159242e-21]\n",
      "  [7.10899956e-19 1.12313636e-09 3.02870404e-21 ... 8.61047213e-16\n",
      "   9.73347046e-19 9.31324186e-21]\n",
      "  [7.24357978e-19 4.76523321e-10 3.04038676e-21 ... 9.67024482e-16\n",
      "   9.73151211e-19 1.14767958e-20]\n",
      "  ...\n",
      "  [1.17063550e-23 5.91776845e-12 6.33478341e-27 ... 3.21320248e-20\n",
      "   1.93243746e-24 5.45376583e-26]\n",
      "  [1.17063550e-23 5.91776845e-12 6.33478341e-27 ... 3.21320248e-20\n",
      "   1.93243746e-24 5.45376583e-26]\n",
      "  [1.17063550e-23 5.91776845e-12 6.33480729e-27 ... 3.21320248e-20\n",
      "   1.93243746e-24 5.45376583e-26]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1.1855e-19, 3.6955e-10, 9.2831e-22,  ..., 1.1747e-15,\n",
       "          1.5845e-19, 1.3016e-21]],\n",
       "\n",
       "        [[7.1090e-19, 1.1231e-09, 3.0287e-21,  ..., 8.6105e-16,\n",
       "          9.7335e-19, 9.3132e-21]],\n",
       "\n",
       "        [[7.2436e-19, 4.7652e-10, 3.0404e-21,  ..., 9.6702e-16,\n",
       "          9.7315e-19, 1.1477e-20]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.1706e-23, 5.9178e-12, 6.3348e-27,  ..., 3.2132e-20,\n",
       "          1.9324e-24, 5.4538e-26]],\n",
       "\n",
       "        [[1.1706e-23, 5.9178e-12, 6.3348e-27,  ..., 3.2132e-20,\n",
       "          1.9324e-24, 5.4538e-26]],\n",
       "\n",
       "        [[1.1706e-23, 5.9178e-12, 6.3348e-27,  ..., 3.2132e-20,\n",
       "          1.9324e-24, 5.4538e-26]]], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(Variable(torch.from_numpy(batch).float()))\n",
    "string = ''.join(labels[0])\n",
    "string = string.strip()\n",
    "string = string.replace(\" \", \"\")\n",
    "\n",
    "output = []\n",
    "for character in string:\n",
    "    number = ord(character) - 65\n",
    "    output.append(number)\n",
    "print output\n",
    "\n",
    "labels_crit = torch.IntTensor(output)\n",
    "\n",
    "label_sizes = torch.IntTensor([len(labels_crit)])\n",
    "probs_sizes = torch.IntTensor([641])\n",
    "\n",
    "arr = out.detach().numpy()\n",
    "arr2 = numpy.empty([1, arr.shape[0], arr.shape[1]])\n",
    "arr2[0]=arr\n",
    "print(arr2)\n",
    "\n",
    "probs = torch.FloatTensor(arr2).transpose(0, 1).contiguous()\n",
    "probs.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=criterion(probs, labels_crit, probs_sizes, label_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1977.4662], grad_fn=<_CTCBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEVENFOURONEOHFIVENINETWO\n",
      "Cost: \n",
      "tensor([1977.4662], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "0\n",
      "VERKETHIRTYFIVETHIRTY\n",
      "Cost: \n",
      "tensor([1998.4708], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "1\n",
      "ENTERSIXTYONE\n",
      "Cost: \n",
      "tensor([2045.3849], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "2\n",
      "SIXTHREEEIGHT\n",
      "Cost: \n",
      "tensor([2045.4657], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "3\n",
      "SUNNYVALE\n",
      "Cost: \n",
      "tensor([2072.2852], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "4\n",
      "BRONXVILLE\n",
      "Cost: \n",
      "tensor([2065.2715], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "5\n",
      "TWELVETWENTYONEFIFTYEIGHT\n",
      "Cost: \n",
      "tensor([1977.4788], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "6\n",
      "ONEFIVETWOONESEVEN\n",
      "Cost: \n",
      "tensor([2015.2604], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "7\n",
      "FOURTWOONEOHONENINESIX\n",
      "Cost: \n",
      "tensor([1993.1598], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "8\n",
      "TWOFOURTHREEEIGHTTHREETWOEIGHT\n",
      "Cost: \n",
      "tensor([1953.3746], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "9\n",
      "STEVEN\n",
      "Cost: \n",
      "tensor([2094.5964], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "10\n",
      "ENTERFIVE\n",
      "Cost: \n",
      "tensor([2072.2295], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "11\n",
      "RUBOUTFXCWNFOUR\n",
      "Cost: \n",
      "tensor([2032.9286], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "12\n",
      "ATTGKEIGHTYFOUR\n",
      "Cost: \n",
      "tensor([2032.9745], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "13\n",
      "SIXSIXFOURSEVENTWONINETHREE\n",
      "Cost: \n",
      "tensor([1967.5508], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "14\n",
      "JETT\n",
      "Cost: \n",
      "tensor([2111.0874], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "15\n",
      "REPEAT\n",
      "Cost: \n",
      "tensor([1511.7782], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "16\n",
      "ENTERSIXSEVEN\n",
      "Cost: \n",
      "tensor([2045.3588], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "17\n",
      "REPEAT\n",
      "Cost: \n",
      "tensor([1511.7548], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "18\n",
      "FOUROHONE\n",
      "Cost: \n",
      "tensor([2072.2219], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "19\n",
      "MAYTWENTYFIRSTNINETEENSIXTY\n",
      "Cost: \n",
      "tensor([1967.6099], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "20\n",
      "TWOSIXEIGHTFOURONESIXONE\n",
      "Cost: \n",
      "tensor([1982.6030], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "21\n",
      "CENTREAVE\n",
      "Cost: \n",
      "tensor([2072.2568], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "22\n",
      "ENTERFOURFIFTYSIX\n",
      "Cost: \n",
      "tensor([2020.9937], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "23\n",
      "MEMORYLANE\n",
      "Cost: \n",
      "tensor([2065.2603], grad_fn=<_CTCBackward>)\n",
      "0\n",
      "24\n",
      "SEVENFOURONEOHFIVENINETWO\n",
      "Cost: \n",
      "tensor([1977.4662], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "0\n",
      "VERKETHIRTYFIVETHIRTY\n",
      "Cost: \n",
      "tensor([1998.4708], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "1\n",
      "ENTERSIXTYONE\n",
      "Cost: \n",
      "tensor([2045.3849], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "2\n",
      "SIXTHREEEIGHT\n",
      "Cost: \n",
      "tensor([2045.4657], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "3\n",
      "SUNNYVALE\n",
      "Cost: \n",
      "tensor([2072.2852], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "4\n",
      "BRONXVILLE\n",
      "Cost: \n",
      "tensor([2065.2715], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "5\n",
      "TWELVETWENTYONEFIFTYEIGHT\n",
      "Cost: \n",
      "tensor([1977.4788], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "6\n",
      "ONEFIVETWOONESEVEN\n",
      "Cost: \n",
      "tensor([2015.2604], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "7\n",
      "FOURTWOONEOHONENINESIX\n",
      "Cost: \n",
      "tensor([1993.1598], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "8\n",
      "TWOFOURTHREEEIGHTTHREETWOEIGHT\n",
      "Cost: \n",
      "tensor([1953.3746], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "9\n",
      "STEVEN\n",
      "Cost: \n",
      "tensor([2094.5964], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "10\n",
      "ENTERFIVE\n",
      "Cost: \n",
      "tensor([2072.2295], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "11\n",
      "RUBOUTFXCWNFOUR\n",
      "Cost: \n",
      "tensor([2032.9286], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "12\n",
      "ATTGKEIGHTYFOUR\n",
      "Cost: \n",
      "tensor([2032.9745], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "13\n",
      "SIXSIXFOURSEVENTWONINETHREE\n",
      "Cost: \n",
      "tensor([1967.5508], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "14\n",
      "JETT\n",
      "Cost: \n",
      "tensor([2111.0874], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "15\n",
      "REPEAT\n",
      "Cost: \n",
      "tensor([1511.7782], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "16\n",
      "ENTERSIXSEVEN\n",
      "Cost: \n",
      "tensor([2045.3588], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "17\n",
      "REPEAT\n",
      "Cost: \n",
      "tensor([1511.7548], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "18\n",
      "FOUROHONE\n",
      "Cost: \n",
      "tensor([2072.2219], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "19\n",
      "MAYTWENTYFIRSTNINETEENSIXTY\n",
      "Cost: \n",
      "tensor([1967.6099], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "20\n",
      "TWOSIXEIGHTFOURONESIXONE\n",
      "Cost: \n",
      "tensor([1982.6030], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "21\n",
      "CENTREAVE\n",
      "Cost: \n",
      "tensor([2072.2568], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "22\n",
      "ENTERFOURFIFTYSIX\n",
      "Cost: \n",
      "tensor([2020.9937], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "23\n",
      "MEMORYLANE\n",
      "Cost: \n",
      "tensor([2065.2603], grad_fn=<_CTCBackward>)\n",
      "1\n",
      "24\n",
      "SEVENFOURONEOHFIVENINETWO\n",
      "Cost: \n",
      "tensor([1977.4662], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "0\n",
      "VERKETHIRTYFIVETHIRTY\n",
      "Cost: \n",
      "tensor([1998.4708], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "1\n",
      "ENTERSIXTYONE\n",
      "Cost: \n",
      "tensor([2045.3849], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "2\n",
      "SIXTHREEEIGHT\n",
      "Cost: \n",
      "tensor([2045.4657], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "3\n",
      "SUNNYVALE\n",
      "Cost: \n",
      "tensor([2072.2852], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "4\n",
      "BRONXVILLE\n",
      "Cost: \n",
      "tensor([2065.2715], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "5\n",
      "TWELVETWENTYONEFIFTYEIGHT\n",
      "Cost: \n",
      "tensor([1977.4788], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "6\n",
      "ONEFIVETWOONESEVEN\n",
      "Cost: \n",
      "tensor([2015.2604], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "7\n",
      "FOURTWOONEOHONENINESIX\n",
      "Cost: \n",
      "tensor([1993.1598], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "8\n",
      "TWOFOURTHREEEIGHTTHREETWOEIGHT\n",
      "Cost: \n",
      "tensor([1953.3746], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "9\n",
      "STEVEN\n",
      "Cost: \n",
      "tensor([2094.5964], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "10\n",
      "ENTERFIVE\n",
      "Cost: \n",
      "tensor([2072.2295], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "11\n",
      "RUBOUTFXCWNFOUR\n",
      "Cost: \n",
      "tensor([2032.9286], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "12\n",
      "ATTGKEIGHTYFOUR\n",
      "Cost: \n",
      "tensor([2032.9745], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "13\n",
      "SIXSIXFOURSEVENTWONINETHREE\n",
      "Cost: \n",
      "tensor([1967.5508], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "14\n",
      "JETT\n",
      "Cost: \n",
      "tensor([2111.0874], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "15\n",
      "REPEAT\n",
      "Cost: \n",
      "tensor([1511.7782], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "16\n",
      "ENTERSIXSEVEN\n",
      "Cost: \n",
      "tensor([2045.3588], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "17\n",
      "REPEAT\n",
      "Cost: \n",
      "tensor([1511.7548], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "18\n",
      "FOUROHONE\n",
      "Cost: \n",
      "tensor([2072.2219], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "19\n",
      "MAYTWENTYFIRSTNINETEENSIXTY\n",
      "Cost: \n",
      "tensor([1967.6099], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "20\n",
      "TWOSIXEIGHTFOURONESIXONE\n",
      "Cost: \n",
      "tensor([1982.6030], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "21\n",
      "CENTREAVE\n",
      "Cost: \n",
      "tensor([2072.2568], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "22\n",
      "ENTERFOURFIFTYSIX\n",
      "Cost: \n",
      "tensor([2020.9937], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "23\n",
      "MEMORYLANE\n",
      "Cost: \n",
      "tensor([2065.2603], grad_fn=<_CTCBackward>)\n",
      "2\n",
      "24\n",
      "SEVENFOURONEOHFIVENINETWO\n",
      "Cost: \n",
      "tensor([1977.4662], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "0\n",
      "VERKETHIRTYFIVETHIRTY\n",
      "Cost: \n",
      "tensor([1998.4708], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "1\n",
      "ENTERSIXTYONE\n",
      "Cost: \n",
      "tensor([2045.3849], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "2\n",
      "SIXTHREEEIGHT\n",
      "Cost: \n",
      "tensor([2045.4657], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "3\n",
      "SUNNYVALE\n",
      "Cost: \n",
      "tensor([2072.2852], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "4\n",
      "BRONXVILLE\n",
      "Cost: \n",
      "tensor([2065.2715], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "5\n",
      "TWELVETWENTYONEFIFTYEIGHT\n",
      "Cost: \n",
      "tensor([1977.4788], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "6\n",
      "ONEFIVETWOONESEVEN\n",
      "Cost: \n",
      "tensor([2015.2604], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "7\n",
      "FOURTWOONEOHONENINESIX\n",
      "Cost: \n",
      "tensor([1993.1598], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "8\n",
      "TWOFOURTHREEEIGHTTHREETWOEIGHT\n",
      "Cost: \n",
      "tensor([1953.3746], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "9\n",
      "STEVEN\n",
      "Cost: \n",
      "tensor([2094.5964], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "10\n",
      "ENTERFIVE\n",
      "Cost: \n",
      "tensor([2072.2295], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "11\n",
      "RUBOUTFXCWNFOUR\n",
      "Cost: \n",
      "tensor([2032.9286], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "12\n",
      "ATTGKEIGHTYFOUR\n",
      "Cost: \n",
      "tensor([2032.9745], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "13\n",
      "SIXSIXFOURSEVENTWONINETHREE\n",
      "Cost: \n",
      "tensor([1967.5508], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "14\n",
      "JETT\n",
      "Cost: \n",
      "tensor([2111.0874], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "15\n",
      "REPEAT\n",
      "Cost: \n",
      "tensor([1511.7782], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "16\n",
      "ENTERSIXSEVEN\n",
      "Cost: \n",
      "tensor([2045.3588], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "17\n",
      "REPEAT\n",
      "Cost: \n",
      "tensor([1511.7548], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "18\n",
      "FOUROHONE\n",
      "Cost: \n",
      "tensor([2072.2219], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "19\n",
      "MAYTWENTYFIRSTNINETEENSIXTY\n",
      "Cost: \n",
      "tensor([1967.6099], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "20\n",
      "TWOSIXEIGHTFOURONESIXONE\n",
      "Cost: \n",
      "tensor([1982.6030], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "21\n",
      "CENTREAVE\n",
      "Cost: \n",
      "tensor([2072.2568], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "22\n",
      "ENTERFOURFIFTYSIX\n",
      "Cost: \n",
      "tensor([2020.9937], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "23\n",
      "MEMORYLANE\n",
      "Cost: \n",
      "tensor([2065.2603], grad_fn=<_CTCBackward>)\n",
      "3\n",
      "24\n",
      "SEVENFOURONEOHFIVENINETWO\n",
      "Cost: \n",
      "tensor([1977.4662], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "0\n",
      "VERKETHIRTYFIVETHIRTY\n",
      "Cost: \n",
      "tensor([1998.4708], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "1\n",
      "ENTERSIXTYONE\n",
      "Cost: \n",
      "tensor([2045.3849], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "2\n",
      "SIXTHREEEIGHT\n",
      "Cost: \n",
      "tensor([2045.4657], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "3\n",
      "SUNNYVALE\n",
      "Cost: \n",
      "tensor([2072.2852], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "4\n",
      "BRONXVILLE\n",
      "Cost: \n",
      "tensor([2065.2715], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "5\n",
      "TWELVETWENTYONEFIFTYEIGHT\n",
      "Cost: \n",
      "tensor([1977.4788], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "6\n",
      "ONEFIVETWOONESEVEN\n",
      "Cost: \n",
      "tensor([2015.2604], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "7\n",
      "FOURTWOONEOHONENINESIX\n",
      "Cost: \n",
      "tensor([1993.1598], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "8\n",
      "TWOFOURTHREEEIGHTTHREETWOEIGHT\n",
      "Cost: \n",
      "tensor([1953.3746], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "9\n",
      "STEVEN\n",
      "Cost: \n",
      "tensor([2094.5964], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "10\n",
      "ENTERFIVE\n",
      "Cost: \n",
      "tensor([2072.2295], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "11\n",
      "RUBOUTFXCWNFOUR\n",
      "Cost: \n",
      "tensor([2032.9286], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "12\n",
      "ATTGKEIGHTYFOUR\n",
      "Cost: \n",
      "tensor([2032.9745], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "13\n",
      "SIXSIXFOURSEVENTWONINETHREE\n",
      "Cost: \n",
      "tensor([1967.5508], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "14\n",
      "JETT\n",
      "Cost: \n",
      "tensor([2111.0874], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "15\n",
      "REPEAT\n",
      "Cost: \n",
      "tensor([1511.7782], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "16\n",
      "ENTERSIXSEVEN\n",
      "Cost: \n",
      "tensor([2045.3588], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "17\n",
      "REPEAT\n",
      "Cost: \n",
      "tensor([1511.7548], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "18\n",
      "FOUROHONE\n",
      "Cost: \n",
      "tensor([2072.2219], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "19\n",
      "MAYTWENTYFIRSTNINETEENSIXTY\n",
      "Cost: \n",
      "tensor([1967.6099], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "20\n",
      "TWOSIXEIGHTFOURONESIXONE\n",
      "Cost: \n",
      "tensor([1982.6030], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "21\n",
      "CENTREAVE\n",
      "Cost: \n",
      "tensor([2072.2568], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "22\n",
      "ENTERFOURFIFTYSIX\n",
      "Cost: \n",
      "tensor([2020.9937], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "23\n",
      "MEMORYLANE\n",
      "Cost: \n",
      "tensor([2065.2603], grad_fn=<_CTCBackward>)\n",
      "4\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "num_epochs = 5\n",
    "\n",
    "j = 0\n",
    "\n",
    "while i < num_epochs:\n",
    "    j=0\n",
    "    \n",
    "    net.train()\n",
    "    while j < 25:\n",
    "        batch = []\n",
    "\n",
    "        index = 0\n",
    "        #print(len(Ms[j][0].T))\n",
    "    \n",
    "        for index in Ms[j][0].T:\n",
    "            x = numpy.array([[index]])\n",
    "            batch.append(x)\n",
    "         \n",
    "        batch = numpy.stack(batch, axis=0)\n",
    "        #print(batch.shape)\n",
    "        \n",
    "        out = net(Variable(torch.from_numpy(batch).float()))\n",
    "        string = ''.join(labels[j])\n",
    "        string = string.strip()\n",
    "        string = string.replace(\" \", \"\")\n",
    "        print(string)\n",
    "        output = []\n",
    "        for character in string:\n",
    "            number = ord(character) - 65\n",
    "            output.append(number)\n",
    "        #print output\n",
    "\n",
    "        labels_crit = torch.IntTensor(output)\n",
    "\n",
    "        label_sizes = torch.IntTensor([len(labels_crit)])\n",
    "        probs_sizes = torch.IntTensor([641])\n",
    "\n",
    "        arr = out.detach().numpy()\n",
    "        arr2 = numpy.empty([1, arr.shape[0], arr.shape[1]])\n",
    "        arr2[0]=arr\n",
    "        #print(arr2)\n",
    "\n",
    "        probs = torch.FloatTensor(arr2).transpose(0, 1).contiguous()\n",
    "        probs.requires_grad_(True)\n",
    "        #labels_crit.requires_grad_(True)\n",
    "        \n",
    "        cost=criterion(probs, labels_crit, probs_sizes, label_sizes)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        print(\"Cost: \")\n",
    "        print(cost)\n",
    "        print(i)\n",
    "        print(j)\n",
    "        j = j + 1\n",
    "        optimizer.step()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
