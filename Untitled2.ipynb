{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from warpctc_pytorch import CTCLoss\n",
    "import numpy\n",
    "ctc_loss = CTCLoss()\n",
    "# expected shape of seqLength x batchSize x alphabet_size\n",
    "probs = torch.FloatTensor([[[0.1, 0.6, 0.1, 0.1, 0.1], [0.1, 0.1, 0.6, 0.1, 0.1]]]).transpose(0, 1).contiguous()\n",
    "labels = torch.IntTensor([1, 2])\n",
    "label_sizes = torch.IntTensor([2])\n",
    "probs_sizes = torch.IntTensor([2])\n",
    "probs.requires_grad_(True)  # tells autograd to compute gradients for probs\n",
    "cost = ctc_loss(probs, labels, probs_sizes, label_sizes)\n",
    "cost.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d, Conv1d\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv_1): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (l_1): Linear(in_features=32, out_features=100, bias=True)\n",
      "  (l_out): Linear(in_features=100, out_features=5, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# hyperameters of the model\n",
    "num_classes = 5\n",
    "channels = 1\n",
    "height = 5\n",
    "width = 2\n",
    "num_filters_conv1 = 16\n",
    "kernel_size_conv1 = 1 # [height, width]\n",
    "stride_conv1 = 1 # [stride_height, stride_width]\n",
    "kernel_size_pool1 = 1\n",
    "stride_pool1 = 1\n",
    "num_l1 = 100\n",
    "padding_conv1 = 0\n",
    "dilation=1\n",
    "\n",
    "def compute_conv_dim(dim_size):\n",
    "    return int((dim_size - kernel_size_conv1 + 2 * padding_conv1) / stride_conv1 + 1)\n",
    "\n",
    "def compute_maxPool_dim(dim_size):\n",
    "    return int((dim_size - kernel_size_pool1 + 2 * padding_conv1) / stride_pool1 + 1)\n",
    "\n",
    "def comput_conv_1d_dim(dim_size):\n",
    "    return int((dim_size+2*padding_conv1-dilation*(kernel_size_conv1-1) - 1)/stride_conv1 + 1)\n",
    "    \n",
    "def comput_maxPool_dim(dim_size):\n",
    "    return int((dim_size+2*padding_conv1-dilation*(kernel_size_pool1-1) - 1)/stride_pool1 + 1)\n",
    "\n",
    "# define network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #out_dim = (input_dim - filter_dim + 2 * padding) / stride + 1\n",
    "        self.conv_1 = Conv2d(in_channels=channels,\n",
    "                             out_channels=num_filters_conv1,\n",
    "                             kernel_size=kernel_size_conv1,\n",
    "                             stride=stride_conv1)\n",
    "        \n",
    "       # self.maxPool_1 = MaxPool2d(2, stride=2)\n",
    "        \n",
    "        self.conv_out_height = compute_conv_dim(height)\n",
    "        self.conv_out_width = compute_conv_dim(width)\n",
    "      #  self.conv_out_height = compute_maxPool_dim(self.conv_out_height)\n",
    "      #  self.conv_out_width = compute_maxPool_dim(self.conv_out_width)\n",
    "        \n",
    "        # add dropout to network\n",
    "        #self.dropout = Dropout2d(p=0.5)\n",
    "        self.l1_in_features = num_filters_conv1*self.conv_out_width\n",
    "        #self.l1_in_features = channels * height * width\n",
    "        \n",
    "        self.l_1 = Linear(in_features=self.l1_in_features, \n",
    "                          out_features=num_l1,\n",
    "                          bias=True)\n",
    "        self.l_out = Linear(in_features=num_l1, \n",
    "                            out_features=num_classes,\n",
    "                            bias=False)\n",
    "    \n",
    "    def forward(self, x): # x.size() = [batch, channel, height, width]\n",
    "        x = relu(self.conv_1(x))\n",
    "        #x = self.maxPool_1(x)\n",
    "        # torch.Tensor.view: http://pytorch.org/docs/master/tensors.html?highlight=view#torch.Tensor.view\n",
    "        #   Returns a new tensor with the same data as the self tensor,\n",
    "        #   but of a different size.\n",
    "        # the size -1 is inferred from other dimensions \n",
    "        #print(x.shape)#NCHW to HCNW\n",
    "        x=x.permute(0, 2, 1, 3)\n",
    "        #print(x.shape)\n",
    "        x=x.contiguous()\n",
    "        x = x.view(1, self.conv_out_height, self.l1_in_features)\n",
    "        #print(x.shape)\n",
    "        #x = self.dropout(relu(self.l_1(x)))\n",
    "        x = relu(self.l_1(x))\n",
    "        #print(x.shape)\n",
    "        return softmax(self.l_out(x), dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = numpy.empty([5,1, 5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64715801 0.25938183 0.19669304 0.86327342 0.89617698]\n",
      " [0.01161764 0.65876866 0.68804475 0.46002251 0.49834358]\n",
      " [0.59020645 0.6079038  0.68491672 0.93689378 0.36714086]\n",
      " [0.88934532 0.92976987 0.25906369 0.8573994  0.09596173]\n",
      " [0.3108552  0.45216214 0.04994604 0.30259031 0.93478389]]\n",
      "[[0.21192095 0.83646819 0.69787761 0.87380731 0.38436348]\n",
      " [0.38722338 0.42302554 0.68732456 0.93009401 0.96046503]\n",
      " [0.47771811 0.01868009 0.43962558 0.98811545 0.85404804]\n",
      " [0.59922576 0.60232594 0.61542878 0.90748531 0.7052207 ]\n",
      " [0.53838507 0.42913368 0.74481268 0.67253602 0.27737164]]\n",
      "[[0.65192154 0.34374388 0.09167979 0.86410905 0.02437801]\n",
      " [0.13978028 0.43741097 0.67711351 0.72087997 0.91150312]\n",
      " [0.2188677  0.62445679 0.8601249  0.85243001 0.23723294]\n",
      " [0.55991007 0.75165778 0.69800039 0.00878664 0.77735312]\n",
      " [0.48648694 0.38013087 0.12926345 0.87434348 0.68915826]]\n",
      "[[0.11159564 0.39338661 0.8687816  0.71663989 0.36544792]\n",
      " [0.70465212 0.98791416 0.53141428 0.09129472 0.84194843]\n",
      " [0.35931787 0.53541097 0.92366882 0.54388347 0.29469721]\n",
      " [0.17821887 0.7752152  0.51092808 0.84682016 0.79477776]\n",
      " [0.95967176 0.19142728 0.33977349 0.20602595 0.9709441 ]]\n",
      "[[0.54386646 0.19759391 0.14453485 0.88070555 0.52020485]\n",
      " [0.87496946 0.48241462 0.66189095 0.23259252 0.99861149]\n",
      " [0.41859535 0.33337573 0.65474035 0.92939442 0.87831431]\n",
      " [0.98673435 0.17738912 0.71848628 0.15273833 0.07218266]\n",
      " [0.42253772 0.19067623 0.04034639 0.02309597 0.277926  ]]\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(sam):\n",
    "    sample[0] = numpy.random.rand(5,5)\n",
    "    print(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = numpy.empty([5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 3 0 1]\n",
      "[0 1 1 0 2]\n",
      "[1 1 3 1 3]\n",
      "[1 2 0 1 0]\n",
      "[0 3 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "for lab in labels:\n",
    "    lab = numpy.random.randint(0, 4, 5)\n",
    "    print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
